{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other chatbots in the travel industry: Expedia, Booking.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "import random\n",
    "import spacy \n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spacy model: nlp\n",
    "nlp = en_core_web_sm.load()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "with open('data/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goodbye': re.compile(r'bye|see you later|goodbye', re.UNICODE),\n",
       " 'greeting': re.compile(r'hi|how are you|is anyone there|hello|good day|hey',\n",
       " re.UNICODE),\n",
       " 'thanks': re.compile(r\"thanks|thank you|that's helpful\", re.UNICODE)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = {}\n",
    "for intent in intents['intents']:\n",
    "    patterns[intent['tag']] = re.compile('|'.join(intent['patterns']))\n",
    "    \n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message) :\n",
    "            matched_intent = intent\n",
    "    return matched_intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON', 'TIME', 'MONEY', 'QUANTITY', 'FAC']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    print(doc)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends called Mary who have worked at Google since 2010\n",
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary', 'TIME': None, 'MONEY': None, 'QUANTITY': None, 'FAC': None}\n"
     ]
    }
   ],
   "source": [
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "# print(extract_entities('people who graduated from MIT in 1999'))\n",
    "# print(extract_entities('What are the top hotels below $50'))\n",
    "# print(extract_entities('What is the rating for hotel ABC?'))\n",
    "# print(extract_entities('What are the 5 ranking hotels near area ABC in 2019 ?'))\n",
    "# print(extract_entities('Can I buy 200 apples'))\n",
    "# print(extract_entities('What is the rating for hotel ABC?'))\n",
    "# print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement noun phrase chunking. For now is one rule but can increase\n",
    "def extract_entities(text):\n",
    "    pattern = 'NP: {<DT>?<JJ>*<NN>}' #Optional determinant followed by any number of adjectives and then a noun\n",
    "    cp = nltk.RegexpParser(pattern)\n",
    "    cs = cp.parse(text)\n",
    "    print(cs)\n",
    "    represent_chunks(cs)\n",
    "    \n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "def represent_chunks(cs):\n",
    "    iob_tagged = tree2conlltags(cs)\n",
    "    pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Is, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (rating, 'O', ''),\n",
      " (for, 'O', ''),\n",
      " (hotel, 'O', ''),\n",
      " (Abra, 'B', 'PERSON'),\n",
      " (Chu, 'I', 'PERSON'),\n",
      " (better, 'O', ''),\n",
      " (for, 'O', ''),\n",
      " (hotel, 'O', ''),\n",
      " (Google, 'B', 'ORG'),\n",
      " (?, 'O', '')]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "doc = nlp(text)\n",
    "\n",
    "# doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "# pprint([(X.text, X.label_) for X in doc.ents])\n",
    "pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary of rules and get responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'topN', 'patterns': ['What are the top N hotels '], 'responses': ['We operate only in LA, for now.']}\n",
      "{'tag': 'review', 'patterns': ['What are the reviews for '], 'responses': ['The review: ']}\n",
      "{'tag': 'amenities', 'patterns': ['Does hotel X have good Y '], 'responses': ['The review: ']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'amenities': ['Does hotel X have good Y '],\n",
       " 'review': ['What are the reviews for '],\n",
       " 'topN': ['What are the top N hotels ']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {}\n",
    "for intent in intents['rules']:\n",
    "    print(intent)\n",
    "    rules[intent['tag']] = intent['patterns']\n",
    "    \n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the rating for hotel Abra Chu better for hotel Google ?\n"
     ]
    }
   ],
   "source": [
    "text = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_lower = [[w.lower() for w in doc] for doc in docs]\n",
    "# docs_regex= [[w for w in doc if re.search('^[a-z]+$',w)] for doc in docs_lower]\n",
    "# docs_stop = [[w for w in doc if w not in stop_words] for doc in docs_regex]\n",
    "# docs_stem = [[stemmer.stem(w) for w in doc] for doc in docs_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shubham', 'NN'), ('wa', 'NN'), ('asking', 'VBG'), ('whether', 'IN'), ('hotel', 'NN'), ('a', 'DT'), ('is', 'VBZ'), ('better', 'JJR'), ('than', 'IN'), ('hotel', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text_list = [word for word in text.split()]\n",
    "#If last word has a question mark attached, that gets removed also.\n",
    "text_regex = [word for word in text_list if re.search('^[a-z0-9]+$',word)]\n",
    "text_lemma = [lemmatizer.lemmatize(word) for word in text_regex]\n",
    "text_pos = nltk.pos_tag(text_lemma)\n",
    "print(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP shubham/NN)\n",
      "  (NP wa/NN)\n",
      "  asking/VBG\n",
      "  whether/IN\n",
      "  (NP hotel/NN)\n",
      "  a/DT\n",
      "  is/VBZ\n",
      "  better/JJR\n",
      "  than/IN\n",
      "  (NP hotel/NN))\n",
      "[('shubham', 'NN', 'B-NP'),\n",
      " ('wa', 'NN', 'B-NP'),\n",
      " ('asking', 'VBG', 'O'),\n",
      " ('whether', 'IN', 'O'),\n",
      " ('hotel', 'NN', 'B-NP'),\n",
      " ('a', 'DT', 'O'),\n",
      " ('is', 'VBZ', 'O'),\n",
      " ('better', 'JJR', 'O'),\n",
      " ('than', 'IN', 'O'),\n",
      " ('hotel', 'NN', 'B-NP')]\n"
     ]
    }
   ],
   "source": [
    "extract_entities(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  shubham/NN\n",
      "  was/VBD\n",
      "  asking/VBG\n",
      "  whether/IN\n",
      "  hotel/NN\n",
      "  a/DT\n",
      "  is/VBZ\n",
      "  better/JJR\n",
      "  than/IN\n",
      "  hotel/NN\n",
      "  b/NN\n",
      "  ?/.)\n"
     ]
    }
   ],
   "source": [
    "ne_tree = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
