{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "import spacy \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Warning: no model found for 'en_core_web_md'\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the spacy model: nlp\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World !\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(color.BOLD + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Templates to be used throughout \n",
    "bot_template = color.BOLD + \"BOT\" + color.END +\": {0}\"\n",
    "user_template =color.BOLD + \"USER\" + color.END +\": {0}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary of rules (patterns) to find and associated responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {'I want (.*)': ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What about {0}', 'your last birthday')\n"
     ]
    }
   ],
   "source": [
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responseList in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responseList)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return response, phrase\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(responses, \"do you remember your last birthday\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me','you',message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my','your',message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your','my',message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you','me',message)\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your last birthday\n"
     ]
    }
   ],
   "source": [
    "print(replace_pronouns(\"my last birthday\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(responses, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: do you remember your last birthday\n",
      "BOT: Did you think I would forget my last birthday\n",
      "USER: do you think humans should be worried about AI\n",
      "BOT: No chance\n",
      "USER: I want a robot friend\n",
      "BOT: What would it mean if you got a robot friend\n",
      "USER: what if you could be anything you wanted\n",
      "BOT: Do you wish that me could be anything me wanted\n"
     ]
    }
   ],
   "source": [
    "# Send the messages\n",
    "send_message(\"do you remember your last birthday\")\n",
    "send_message(\"do you think humans should be worried about AI\")\n",
    "send_message(\"I want a robot friend\")\n",
    "send_message(\"what if you could be anything you wanted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent and Entity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.update({'default': 'default message', 'goodbye': 'goodbye for now',\\\n",
    " 'greet': 'Hello you! :)', 'thankyou': 'you are very welcome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goodbye': re.compile('bye|farewell'), 'greet': re.compile('hello|hi|hey'), 'thankyou': re.compile('thank|thx')}\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "#     patterns[intent] = re.compile('|'.join(keys))    \n",
    "    patterns[intent] = re.compile(\"|\".join(keys))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message) :\n",
    "            \n",
    "            matched_intent = intent\n",
    "    return matched_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: hello!\n",
      "greet\n",
      "BOT: Hello you! :)\n",
      "USER: bye byeee\n",
      "goodbye\n",
      "BOT: goodbye for now\n",
      "USER: thanks very much!\n",
      "thankyou\n",
      "BOT: you are very welcome\n"
     ]
    }
   ],
   "source": [
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    print(intent)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(\"name|call\")\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile(\"[A-Z]{1}[a-z]*\")\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: my name is David Copperfield\n",
      "BOT: Hello, David Copperfield!\n",
      "USER: call me Ishmael\n",
      "BOT: Hello, Ishmael!\n",
      "USER: People call me Cassandra\n",
      "BOT: Hello, People Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following data has been extracted from ATIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning',\n",
    " ' what flights are available from pittsburgh to baltimore on thursday morning',\n",
    " ' what is the arrival time in san francisco for the 755 am flight leaving washington',\n",
    " ' cheapest airfare from tacoma to orlando',\n",
    " ' round trip fares from pittsburgh to philadelphia under 1000 dollars',\n",
    " ' i need a flight tomorrow from columbus to minneapolis',\n",
    " ' what kind of aircraft is used on a flight from cleveland to dallas',\n",
    " ' show me the flights from pittsburgh to los angeles on thursday',\n",
    " ' all flights from boston to washington',\n",
    " ' what kind of ground transportation is available in denver',\n",
    " ' show me the flights from dallas to san francisco',\n",
    " ' show me the flights from san diego to newark by way of houston',\n",
    " ' what is the cheapest flight from boston to bwi',\n",
    " ' all flights to baltimore after 6 pm',\n",
    " ' show me the first class fares from boston to denver',\n",
    " ' show me the ground transportation in denver',\n",
    " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm',\n",
    " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore',\n",
    " ' please give me the flights from boston to pittsburgh on thursday of next week',\n",
    " ' i would like to fly from denver to pittsburgh on united airlines',\n",
    " ' show me the flights from san diego to newark',\n",
    " ' please list all first class flights on united from denver to baltimore',\n",
    " ' what kinds of planes are used by american airlines',\n",
    " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\",\n",
    " \" i'd like to book a flight from atlanta to denver\",\n",
    " ' which airline serves denver pittsburgh and atlanta',\n",
    " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\",\n",
    " ' atlanta ground transportation',\n",
    " ' i also need service from dallas to boston arriving by noon',\n",
    " ' show me the cheapest round trip fare from baltimore to dallas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =['atis_flight', 'atis_flight', 'atis_flight_time', 'atis_airfare', 'atis_airfare', 'atis_flight', 'atis_aircraft',\\\n",
    " 'atis_flight', 'atis_flight', 'atis_ground_service', 'atis_flight', 'atis_flight', 'atis_flight', 'atis_flight',\\\n",
    "         'atis_airfare', 'atis_ground_service', 'atis_flight', 'atis_flight', 'atis_flight', 'atis_flight', 'atis_flight',\\\n",
    " 'atis_flight', 'atis_aircraft', 'atis_airfare', 'atis_flight', 'atis_airline', 'atis_flight', 'atis_ground_service',\\\n",
    " 'atis_flight', 'atis_airfare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Word vectors set to length 0. This may be because you don't have a model installed or loaded, or because your model doesn't include word vectors. For more info, see the documentation: \nhttps://spacy.io/docs/usage\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1e0d677290bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Save the document's .vector attribute to the corresponding row in X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.vector.__get__ (spacy/tokens/doc.cpp:7291)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mgenexpr (spacy/tokens/doc.cpp:7114)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\tokens\\token.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.vector.__get__ (spacy/tokens/token.cpp:7249)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Word vectors set to length 0. This may be because you don't have a model installed or loaded, or because your model doesn't include word vectors. For more info, see the documentation: \nhttps://spacy.io/docs/usage\n"
     ]
    }
   ],
   "source": [
    "#Calculate the length of sentences using len() and \n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "print(n_sentences, embedding_dim)\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "#     For each sentence, call the nlp object with the sentence as the sole argument. Store the result as doc.\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    \n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [(\"no I don't want to be in the south\", {'south': False}),\n",
    " ('no it should be in the south', {'south': True}),\n",
    " ('no in the south not the north', {'north': False, 'south': True}),\n",
    " ('not north', {'north': False})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negated_ents(phrase):\n",
    "    # Extract the entities using keyword matching\n",
    "    ents = [e for e in [\"south\", \"north\"] if e in phrase]\n",
    "    # Find the index of the final character of each entity\n",
    "    ends = sorted([phrase.index(e) + len(e) for e in ents])\n",
    "    # Initialise a list to store sentence chunks\n",
    "    chunks = []\n",
    "    # Take slices of the sentence up to and including each entitiy\n",
    "    start = 0\n",
    "    for end in ends:\n",
    "        chunks.append(phrase[start:end])\n",
    "        start = end\n",
    "    result = {}\n",
    "    # Iterate over the chunks and look for entities\n",
    "    for chunk in chunks:\n",
    "        for ent in ents:\n",
    "            if ent in chunk:\n",
    "                # If the entity is preceeded by a negation, give it the key False\n",
    "                if \"not\" in chunk or \"n't\" in chunk:\n",
    "                    result[ent] = False\n",
    "                else:\n",
    "                    result[ent] = True\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check that the entities are correctly assigned as True or False\n",
    "for test in tests:\n",
    "    print(negated_ents(test[0]) == test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
